{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2019-12-03 22:48:54.657847\n",
      "Running system command: hdfs dfs -ls /user/tadas/tmp/tests/raw_data/yellow_tripdata_2019-06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0.00/643M [00:00<?, ?KB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-03 22:48:57.295317 Start downloading file: yellow_tripdata_2019-06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 629/643M [00:10<3093:06:58, 57.8KB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-03 22:49:08.183218 Downloaded file: yellow_tripdata_2019-06.csv\n",
      "Running system command: hadoop fs -moveFromLocal -f /tmp/test/yellow_tripdata_2019-06.csv /user/tadas/tmp/tests/raw_data/\n",
      "2019-12-03 22:49:08.183328 Files were moved to HDFS.\n",
      "2019-12-03 22:49:17.928891 Transform file: /user/tadas/tmp/tests/raw_data/yellow_tripdata_2019-06.csv\n",
      "2019-12-03 22:49:18.091406 Write file to parquet: yellow_tripdata\n",
      "Finished at 2019-12-03 22:50:07.288300\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType, TimestampType, DecimalType\n",
    "import pyspark.sql.functions as F\n",
    "import datetime\n",
    "import requests\n",
    "import utils\n",
    "\n",
    "\n",
    "def define_schema(src_name):\n",
    "    \"\"\"\n",
    "    define source file's schema\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'yellow':\n",
    "            StructType([\n",
    "                StructField('corrupted', StringType(), True),\n",
    "                StructField('VendorID', StringType(), True),\n",
    "                StructField('tpep_pickup_datetime', TimestampType(), True),\n",
    "                StructField('tpep_dropoff_datetime', TimestampType(), True),\n",
    "                StructField('passenger_count', IntegerType(), True),\n",
    "                StructField('trip_distance', DecimalType(10, 4), True),\n",
    "                StructField('RatecodeID', StringType(), True),\n",
    "                StructField('store_and_fwd_flag', StringType(), True),\n",
    "                StructField('PULocationID', StringType(), True),\n",
    "                StructField('DOLocationID', StringType(), True),\n",
    "                StructField('payment_type', StringType(), True),\n",
    "                StructField('fare_amount', DecimalType(10, 2), True),\n",
    "                StructField('extra', DecimalType(10, 2), True),\n",
    "                StructField('mta_tax', DecimalType(10, 2), True),\n",
    "                StructField('tip_amount', DecimalType(10, 2), True),\n",
    "                StructField('tolls_amount', DecimalType(10, 2), True),\n",
    "                StructField('improvement_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('total_amount', DecimalType(10, 2), True),\n",
    "                StructField('congestion_surcharge', DecimalType(10, 2), True)\n",
    "            ]),\n",
    "        'green':\n",
    "            StructType([\n",
    "                StructField('corrupted', StringType(), True),\n",
    "                StructField('VendorID', StringType(), True),\n",
    "                StructField('lpep_pickup_datetime', TimestampType(), True),\n",
    "                StructField('lpep_dropoff_datetime', TimestampType(), True),\n",
    "                StructField('store_and_fwd_flag', StringType(), True),\n",
    "                StructField('RatecodeID', StringType(), True),\n",
    "                StructField('PULocationID', StringType(), True),\n",
    "                StructField('DOLocationID', StringType(), True),\n",
    "                StructField('passenger_count', IntegerType(), True),\n",
    "                StructField('trip_distance', DecimalType(10, 4), True),\n",
    "                StructField('fare_amount', DecimalType(10, 2), True),\n",
    "                StructField('extra', DecimalType(10, 2), True),\n",
    "                StructField('mta_tax', DecimalType(10, 2), True),\n",
    "                StructField('tip_amount', DecimalType(10, 2), True),\n",
    "                StructField('tolls_amount', DecimalType(10, 2), True),\n",
    "                StructField('ehail_fee', DecimalType(10, 2), True),\n",
    "                StructField('improvement_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('total_amount', DecimalType(10, 2), True),\n",
    "                StructField('payment_type', StringType(), True),\n",
    "                StructField('trip_type', StringType(), True),\n",
    "                StructField('congestion_surcharge', DecimalType(10, 2), True)\n",
    "            ])\n",
    "    }[src_name]\n",
    "\n",
    "\n",
    "def write_schema(src_name):\n",
    "    \"\"\"\n",
    "    define outgoing file's schema\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'yellow':\n",
    "            StructType([\n",
    "                StructField('VendorID', StringType(), True),\n",
    "                StructField('tpep_pickup_datetime', TimestampType(), True),\n",
    "                StructField('tpep_dropoff_datetime', TimestampType(), True),\n",
    "                StructField('passenger_count', IntegerType(), True),\n",
    "                StructField('trip_distance', DecimalType(10, 4), True),\n",
    "                StructField('RatecodeID', StringType(), True),\n",
    "                StructField('store_and_fwd_flag', StringType(), True),\n",
    "                StructField('PULocationID', StringType(), True),\n",
    "                StructField('DOLocationID', StringType(), True),\n",
    "                StructField('payment_type', StringType(), True),\n",
    "                StructField('fare_amount', DecimalType(10, 2), True),\n",
    "                StructField('extra', DecimalType(10, 2), True),\n",
    "                StructField('mta_tax', DecimalType(10, 2), True),\n",
    "                StructField('tip_amount', DecimalType(10, 2), True),\n",
    "                StructField('tolls_amount', DecimalType(10, 2), True),\n",
    "                StructField('improvement_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('total_amount', DecimalType(10, 2), True),\n",
    "                StructField('congestion_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('file_name', StringType(), True),\n",
    "                StructField('update_date', TimestampType(), True),\n",
    "                StructField('dt', StringType(), True)\n",
    "            ]),\n",
    "        'green':\n",
    "            StructType([\n",
    "                StructField('VendorID', StringType(), True),\n",
    "                StructField('lpep_pickup_datetime', TimestampType(), True),\n",
    "                StructField('lpep_dropoff_datetime', TimestampType(), True),\n",
    "                StructField('store_and_fwd_flag', StringType(), True),\n",
    "                StructField('RatecodeID', StringType(), True),\n",
    "                StructField('PULocationID', StringType(), True),\n",
    "                StructField('DOLocationID', StringType(), True),\n",
    "                StructField('passenger_count', IntegerType(), True),\n",
    "                StructField('trip_distance', DecimalType(10, 4), True),\n",
    "                StructField('fare_amount', DecimalType(10, 2), True),\n",
    "                StructField('extra', DecimalType(10, 2), True),\n",
    "                StructField('mta_tax', DecimalType(10, 2), True),\n",
    "                StructField('tip_amount', DecimalType(10, 2), True),\n",
    "                StructField('tolls_amount', DecimalType(10, 2), True),\n",
    "                StructField('ehail_fee', DecimalType(10, 2), True),\n",
    "                StructField('improvement_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('total_amount', DecimalType(10, 2), True),\n",
    "                StructField('payment_type', StringType(), True),\n",
    "                StructField('trip_type', StringType(), True),\n",
    "                StructField('congestion_surcharge', DecimalType(10, 2), True),\n",
    "                StructField('file_name', StringType(), True),\n",
    "                StructField('update_date', TimestampType(), True),\n",
    "                StructField('dt', StringType(), True)\n",
    "            ]),\n",
    "        'corrupted':\n",
    "            StructType([\n",
    "                StructField('corrupted', StringType(), True),\n",
    "                StructField('file_name', StringType(), True),\n",
    "                StructField('update_date', TimestampType(), True)\n",
    "            ])\n",
    "    }[src_name]\n",
    "\n",
    "\n",
    "def transform_file(file_path, schema, partition, spark, file_name):\n",
    "    print(str(datetime.datetime.now()) + \" Transform file: {}\".format(file_path + file_name))\n",
    "    update_date = datetime.datetime.now()\n",
    "\n",
    "    df_source_file = spark.read \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .option(\"quote\", \"\\\"\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"false\") \\\n",
    "        .option(\"columnNameOfCorruptRecord\", \"corrupted\") \\\n",
    "        .csv(file_path + file_name, schema=schema).cache()\n",
    "\n",
    "    df_transformed = df_source_file \\\n",
    "        .filter(F.col(\"corrupted\").isNull()) \\\n",
    "        .withColumn(\"file_name\", F.lit(file_name).cast('string')) \\\n",
    "        .withColumn(\"update_date\", F.lit(update_date).cast('timestamp')) \\\n",
    "        .withColumn(\"dt\", F.lit(partition).cast('string')) \\\n",
    "        .drop(F.col(\"corrupted\"))\n",
    "\n",
    "    df_corrupted = df_source_file \\\n",
    "        .select(F.col(\"corrupted\").alias(\"corrupted\").cast('string'),\n",
    "                F.lit(file_name).alias(\"file_name\").cast('string'),\n",
    "                F.lit(update_date).alias(\"update_date\").cast('timestamp')) \\\n",
    "        .filter(F.col(\"corrupted\").isNotNull())\n",
    "\n",
    "    return df_transformed, df_corrupted\n",
    "\n",
    "\n",
    "def download_file(local_dir, file_name, overwrite=False):\n",
    "    \"\"\"download file from url \"\"\"\n",
    "    dataset_url = 'https://s3.amazonaws.com/nyc-tlc/trip+data/{}'.format(file_name)\n",
    "\n",
    "    request = requests.get(dataset_url, stream=True)\n",
    "    print(str(datetime.datetime.now()) + \" Start downloading file: {}\".format(file_name))\n",
    "    if overwrite:\n",
    "        utils.write_file_chunks(request, file_name, local_dir)\n",
    "    else:\n",
    "        if utils.file_exists(request, file_name, local_dir):\n",
    "            print(\"File {} already downloaded.\".format(file_name))\n",
    "        else:\n",
    "            utils.write_file_chunks(request, file_name, local_dir)\n",
    "    print(str(datetime.datetime.now()) + \" Downloaded file: {}\".format(file_name))\n",
    "\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def load_file_hdfs(local_dir, hdfs_path, file_name, overwrite=False):\n",
    "    utils.create_tmp_local_dir(local_dir)\n",
    "    hdfs_file_exist = utils.hdfs_file_exists(hdfs_path, file_name)\n",
    "    if (overwrite & hdfs_file_exist) | ((not overwrite) & (not hdfs_file_exist)):\n",
    "        file_name = download_file(local_dir=local_dir, file_name=file_name, overwrite=overwrite)\n",
    "        utils.move_local_to_hdfs(local_dir=local_dir, local_file=file_name, hdfs_path=hdfs_path)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting at \" + str(datetime.datetime.now()))\n",
    "    # to_do move to parameters file\n",
    "    hdfs_raw_path = \"/user/tadas/tmp/tests/raw_data/\"\n",
    "    local_dir = \"/tmp/test/\"\n",
    "    hdfs_path = \"/user/tadas/tmp/tests/dl_data/\"\n",
    "    # yellow or green\n",
    "    taxi_color = \"yellow\"\n",
    "    year = 2019\n",
    "    month = 6\n",
    "    overwrite_file = False\n",
    "\n",
    "    file_name = '{}_tripdata_{}-{}.csv'.format(taxi_color, year, str(month).zfill(2))\n",
    "    dt_partition = '{}-{}-01'.format(year, str(month).zfill(2))\n",
    "\n",
    "    spark = utils.get_spark_session(\"ny_taxi\")\n",
    "\n",
    "    load_file_hdfs(local_dir=local_dir, hdfs_path=hdfs_raw_path, file_name=file_name, overwrite=overwrite_file)\n",
    "    df_transform, df_corrupted = transform_file(hdfs_raw_path, schema=define_schema(taxi_color),\n",
    "                                  partition=dt_partition, spark=spark, file_name=file_name)\n",
    "    utils.write_parquet(df=df_transform, hdfs_path=hdfs_path, file_name='{}_tripdata'.format(taxi_color), \\\n",
    "                        schema=write_schema(taxi_color))\n",
    "    if df_corrupted.count() != 0:\n",
    "        utils.write_parquet(df=df_corrupted, hdfs_path=hdfs_path, file_name='{}_corrupted'.format(taxi_color), \\\n",
    "                            schema=write_schema(\"corrupted\"))\n",
    "\n",
    "    print(\"Finished at \" + str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.4.0 Python 3",
   "language": "python",
   "name": "spark240python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
